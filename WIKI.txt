KAFKA PRODUCER

	Optional Partition Key

		IF KEY IS PRESENT, USING HASHING ALGORITHM
		ELSE USE ROUND ROBIN FOR PARTITIONING

	Partition Strategy:


	Timestamp:
		Create Time : When message is produced
		Log Append Time : Whn message is received in broker

		Can use only one approach.

		message.timestamp.size

	Send: usage buffering
		Asynchronous
		Network Optimiztion

		Use background I/O thread and add combine multiple records for diff thread to same buffer.

		I/O thread timeout
		Default Producer RAM usage is 32MB.
		Change memory usage by adding buffer.memory configuration. (topic config)

		Retry producer configuration

	Producer is threadsafe.

Advanced Producer


	1. KAFKA Exactly Once (Idempotence)
		Message commit : Once leader receives and follower pulls from leader.

		Producer Retry: (ATleast once)
			Producer doesn't get acknowledgement from I/O from broker.
			Broker stores message and sends response, but there is network error
			Broker stores message and sends response, but Producer timedout.

		Without retry:
			At most once

		Exactly Once:
			Idempotence Producer Configuration
			enable.idempotence=true

			Enable internal id for producer instance
				Perform initial handshake with leader broker and ask for unique producer id.
				Broker dynmaically assign uniqued id to each producer.
			Message Sequence Number
				Producer will assign unique sequence number to each message.
				Starts with zero and increase per partition.

			When the request is send, broker knows the duplicate and missing sequence number.

		Issue :
			Sending duplicate message at application level, System can't guarantee duplicate method.
			Idempotence guarantees for the producer retry.
			Will work in the cass retry happnes in the producer try and not application retry.

	2. Transaction Producer

		Supports atomicity. All messages are writen to all partition or none.

		precondition
			replication factor for each topic shd be >= 3
			min.insync.replicas >= 2

			Add below command while creating topic
			--config min.insync.replicas = 2

			Enable TRANSACTIONAL_ID_CONFIG in in Kafka ProducerConfig.
			The transaction id shd be unique for each Producer instance. If you run 2 producer instance, the TRANSACTIONAL_ID_CONFIG shd be diff.

		e.g. create 2 topic



KAFKA STREAM
	java application
	unbounded
	No need to create cluster
	highly scalable, elastic and fault toleranr
	Exactly once
	One record at a time
	Sits betwwen query and batch process

	Design
		Identify and model events


Architecture

	Only one controller , controller is same as broker
	Zookeper acts a database to keep kafka conttoller information.

	Kafa broker maneges 2 task , loeader and follower partitiion.


Communication
	Producer request for metadata from anuy broker.
	producer conencts to broker for a leader.

	follower broker only job is to synup with leader so that it can become leader.

	Leader have addtional job and keep track of followers and In Sync Replica and kept in zookeper

	Defaukt value of nto to far is 10 sec (to verify in sync)

	commited vs uncommited message

	commited : Syncup and available in follwers.

		After producer receives acknow, the messages are commited.
		For uncommited message, the producer can resend.

		Optional Min replicas : if the min replica is less than availab le replica (replica machine crashes), broker will not take request

Kafka Consumer

	Parallel read in single application.

	Consumer Group

		Will consumer reads same message? No
		One consumer owns partition at a particular time.
		Consumer will not share same partition.

		How consumer enters/exits group?


		Group Coordinator :
			Co-ordinator
				Kafka broker (leader) becomes group coordinator.
				Manage list of consumer in group.
				Initiates a rebalance activities. (*** During rebalance activities, no consumer can read any records)
				Communicate to consumer member about partition

			Consumer Leader
				The first consumer sending request becomes consumer leader.
				Execute rebalance activities


	Offset
		Current Offset 		:	Sent records (Avoids sending same records to consumer)
							:	Depends on the consumer poll receives.

		Commited Offset 	: 	Processed records.
								Identifies the indicator that conumer has succesfull processed.
								Very very important when partition rebalance is done.

			Offset Commit

				AutoCommit	:
								enable.auto.commit      (By default : true )
								auto.commit.interval.ms (By default : 5 sec )

								Issue :
										Consumer receievs first 10 records
										Consumer takes 4 sec to process and again makes new call to poll.
										Since 5 sec is not passed, consumer will not commit.

										And meanwhile rebalance has occured and partition is assigned to diff consumer.
										New consumer receievs first 10 records

				Manual Commit:

								enable.auto.commit: false

						Commit Sync : Reliable but block call and  an retry for recovery

						Commit Async : No Retry


	Cnotrolling
		1. partition assignment
		2. Committed Offset




